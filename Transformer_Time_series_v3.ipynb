{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "plot_path = \"plots/\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Real server data\n",
    "\n",
    "root_path = \"Data/Ant_202007/\"\n",
    "\n",
    "\n",
    "cif = pd.read_json(root_path+'cif.json', orient='index')\n",
    "paycore = pd.read_json(root_path+'paycore.json', orient='index')\n",
    "paydecision = pd.read_json(root_path+'paydecision.json', orient='index')\n",
    "paydecision2 = pd.read_json(root_path+'paydecision2.json', orient='index')\n",
    "paydecision3 = pd.read_json(root_path+'paydecision3.json', orient='index')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"time_stamp\"] = cif.index\n",
    "df[\"cif\"] = cif[0].values\n",
    "df[\"paycore\"] = paycore[0].values\n",
    "df[\"paydecision\"] = paydecision[0].values\n",
    "df[\"paydecision2\"] = paydecision2[0].values\n",
    "df[\"paydecision3\"] = paydecision3[0].values\n",
    "\n",
    "# Optional\n",
    "if False:\n",
    "    df.to_csv(root_path+\"fusion.csv\")\n",
    "\n",
    "    \n",
    "# convert time stamp\n",
    "df['time_stamp'] = pd.to_datetime(df['time_stamp'])\n",
    "names_array = np.array(df.keys()[1:],dtype=\"str\")\n",
    "os.listdir(root_path)\n",
    "\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # calculate previous hour high low:\n",
    "    # convert to seconds\n",
    "    temp = df['time_stamp'] - min(df['time_stamp'])\n",
    "    temp = temp.dt.total_seconds().astype(int)\n",
    "    df[\"hours\"] = temp//3600\n",
    "\n",
    "    h_max = max(df[\"hours\"])+1\n",
    "\n",
    "    for n in range(len(names_array)):\n",
    "        df[names_array[n]+\"_open\"] = df[names_array[n]]\n",
    "        df[names_array[n]+\"_close\"] = df[names_array[n]]\n",
    "        df[names_array[n]+\"_max\"] = df[names_array[n]]\n",
    "        df[names_array[n]+\"_min\"] = df[names_array[n]]\n",
    "\n",
    "    for j in range(1,h_max):\n",
    "        mask_j = df[\"hours\"]==j-1\n",
    "        max_val = df[mask_j][names_array].max(axis=0).values\n",
    "        min_val = df[mask_j][names_array].max(axis=0).values\n",
    "        open_val = df[mask_j][names_array].values[0,:]\n",
    "        close_val = df[mask_j][names_array].values[-1,:]\n",
    "        mask_i = df[\"hours\"]==j\n",
    "        r = df[mask_i][names_array].shape[0]\n",
    "        df.loc[mask_i,[r+\"_open\" for r in names_array]] = np.tile(open_val,(r,1))\n",
    "        df.loc[mask_i,[r+\"_close\" for r in names_array]] = np.tile(close_val,(r,1))\n",
    "\n",
    "        df.loc[mask_i,[r+\"_max\" for r in names_array]] = np.tile(max_val,(r,1))\n",
    "        df.loc[mask_i,[r+\"_min\" for r in names_array]] = np.tile(min_val,(r,1))\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 60, 32]), TensorShape([16, 8, 60, 60]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale dot attention:\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    # Dimension of k\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "    # calculate attention weight:\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n",
    "\n",
    "# Multi-head Attention:\n",
    "# This is what we use\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \n",
    "        # Always use Super to inheriatte and avoid extra code.\n",
    "        assert d_model%num_heads==0\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        # sanity check:\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        # Q K W:\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/transpose : perm\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        ## Can add mask here to do log-sparse attention\n",
    "        \n",
    "        return output, attention_weights\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "# check our Multi-head attention:\n",
    "# D_model must be divided by num_head\n",
    "\n",
    "n_d_model=32\n",
    "temp_mha = MultiHeadAttention(d_model=n_d_model, num_heads=8)\n",
    "y = tf.random.uniform((16, 60, n_d_model))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "# include encoder and decoder:\n",
    "num_layers = 2\n",
    "d_model=512\n",
    "num_heads =8\n",
    "\n",
    "dff = 1024\n",
    "\n",
    "input_length = 180\n",
    "output_length = 1\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    # Two FC layers:\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    # Here we use a 0.1 dropout rate as default\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "        return out2\n",
    "\n",
    "class Transformer(tf.keras.models.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads,input_length,output_length,dff,rate=0.1,training=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.dff = dff\n",
    "        self.rate = rate\n",
    "        self.training = training\n",
    "        \n",
    "    def encoder_layer(self,x):\n",
    "        # no mask for now\n",
    "        mask = None\n",
    "        training = self.training\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mha = MultiHeadAttention(self.d_model, self.num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(self.d_model, self.dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.rate)\n",
    "        #print(\"check\",x.shape)\n",
    "        #print(\"1\",x.shape)\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        #print(\"2\",attn_output.shape)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        #print(\"3\",out1.shape)\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        out2 = self.layernorm2(out1 + ffn_output) \n",
    "        #print(\"4\",out2.shape)\n",
    "        return out2\n",
    "        \n",
    "        \n",
    "\n",
    "    def encoder(self,x):\n",
    "        training = self.training\n",
    "        # simply encode x into d_model\n",
    "        \n",
    "        ## need to change: still need embedding here:\n",
    "        \n",
    "        \n",
    "        x = Dense(d_model)(x)\n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        # no positional encoding for now\n",
    "        \n",
    "        x = Dropout(self.rate)(x, training=training)\n",
    "        \n",
    "        # encoder layer: based on mha:\n",
    "        \n",
    "        self.enc_layers = [self.encoder_layer for _ in range(num_layers)]\n",
    "        #print(x.shape)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    def DecoderLayer(self,x,enc_output):\n",
    "        training = self.training\n",
    "        self.mha1 = MultiHeadAttention(self.d_model, self.num_heads)\n",
    "        self.mha2 = MultiHeadAttention(self.d_model, self.num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(self.d_model, self.dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(self.rate)\n",
    "        \n",
    "        # no mask for now\n",
    "        look_ahead_mask = None\n",
    "        padding_mask = None\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "    def decoder(self,x,enc_output):\n",
    "        training = self.training\n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = Dense(d_model)(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        x = Dropout(self.rate)(x,training=training)\n",
    "        \n",
    "        \n",
    "        self.dec_layers = [self.DecoderLayer\n",
    "                           for _ in range(self.num_layers)]\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "    \n",
    "    def call(self,inp,tar,training=False):\n",
    "        self.training = training\n",
    "        \n",
    "        \n",
    "        enc_output = self.encoder(inp)\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(self.output_length)\n",
    "        dec_output = tf.keras.layers.Flatten()(dec_output)\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        #print(\"check\",final_output.shape,dec_output.shape)\n",
    "        \n",
    "        return final_output, attention_weights\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,input_length=input_length,output_length=output_length,dff=dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = tf.random.uniform((64, 180), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 1), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "temp_input = tf.cast(temp_input,dtype=tf.float32)\n",
    "temp_target = tf.cast(temp_target,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder(x=temp_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.encoder(x=temp_input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, _ = model.decoder(x=temp_input,enc_output=model.encoder(x=temp_input))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output, attention_weights = model.call(temp_input,temp_target,training=True)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f79d001fca0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(temp_target,final_output[:,0],\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model:\n",
    "temp_input = tf.random.uniform((64, 180), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 1), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "temp_input = tf.cast(temp_input,dtype=tf.float32)\n",
    "temp_target = tf.cast(temp_target,dtype=tf.float32)\n",
    "model = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,input_length=input_length,output_length=output_length,dff=dff,training=True)\n",
    "\n",
    "\n",
    "fn_out, _ = model.call(temp_input,-temp_target,training=True)\n",
    "fn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV5bno8d+TOQQSyMCUAAlhMiACRurYqtSKQ6XHaov23qvVc7xt8Xaw57T6Oa2n9dR7jx0OVavH2qpFjxaH2pqqdUStVQRiQQQUSDZjGLLDEEggQMJz/1hvwibuJDvJXtk72c/388kna6/hXc/egTx51/uuZ4mqYowxxkRDUqwDMMYYM3BYUjHGGBM1llSMMcZEjSUVY4wxUWNJxRhjTNSkxDqAWMrPz9fi4uJYh2GMMf3K+++/X6eqBeG2JXRSKS4uprKyMtZhGGNMvyIiWzraZpe/jDHGRI0lFWOMMVFjScUYY0zUWFIxxhgTNZZUjDHGRI2vSUVE5orIehGpEpFbw2xPF5En3fZlIlIcsu02t369iFzcVZsi8raIrHJfO0TkT36+N2OMMZ/k25RiEUkG7gMuArYDK0SkQlXXhex2I7BPVSeIyHzgLuDLIlIGzAemAqOB10RkkjsmbJuqel7Iuf8APOfXezPGGBOenz2V2UCVqgZU9SiwGJjXbp95wCK3/AwwR0TErV+sqkdUdRNQ5drrsk0RyQYuBAZcT+Vo83F+v3wrx1qOxzoUY4wJy8+kUghsC3m93a0Lu4+qNgP1QF4nx0bS5heA11X1QLigROQmEakUkcpgMNitNxRrT7+/jdue/ZCH/rYp1qEYY0xYA3Gg/hrg9x1tVNUHVbVcVcsLCsJWGYhbexuOAvBOVV2MIzHGmPD8TCo1wJiQ10VuXdh9RCQFyAH2dHJsp22KSD7eJbIXovIO4symPY0ArNi8l0NHm2McjTHGfJKfSWUFMFFESkQkDW/gvaLdPhXAdW75KmCJes83rgDmu9lhJcBEYHkEbV4FPK+qTb69qxiqDjYiAk3HjvPm+v516c4Ykxh8SypujORm4GXgI+ApVV0rIneIyBVut4eAPBGpAm4BbnXHrgWeAtYBLwELVLWlozZDTjufTi599WeqSiDYwPwzxpKblcZf1uyKdUjGGPMJvlYpVtUXgRfbrbs9ZLkJuLqDY+8E7oykzZBt5/ci3LgWbDjCwaZmJo0YDIygYtUOmo61kJGaHOvQjDGmzUAcqB+QAkFvPGV8wWDmThtF49EW3t5oA/bGmPhiSaWfaE0qpQVZnF2ax9BBqfz5gx0xjsoYY05mSaWfqA42kJGaxOicTFKTk7js1FG8sm4XDUdsFpgxJn5YUuknAsEGSvIHk5QkAFw5q5CmY8d52QbsjTFxxJJKP1EdbGR8QVbb61ljhzE2dxB/XNn+1h9jjIkdSyr9wJHmFrbvO0Rp/omkIiJ8YWYh71TXsat+QN6WY4zphyyp9ANb9hziuELp8MEnrf+HmYWoQsUH1lsxxsQHSyr9QHVtAwDj809OKiX5WcwYM5Q/vF+DV4jAGGNiy5JKPxCoa71HJesT264uL2L97oOs2ra/r8MyxphPsKTSD1TXNjAyO4Os9E8WQJg3o5BBack8sWxrDCIzxpiTWVLpB6rrGsP2UgAGp6cwb8Zo/rx6BweajvVxZMYYczJLKnFOVQnUNlBaMLjDfa6dPY6mY8f5k00vNsbEmCWVOBdsOMLBI80d9lQATi3KYVphNk8s22oD9saYmLKkEudO1PzquKcCXm/l410H+fvWfX0RljHGhGVJJc5VB9104k56KgDzZoxmSEYKD7+zuQ+iMsaY8CypxLlAsLGtkGRnstJTuGb2WF5as4vt+w71UXTGGHMySypxrrpdIcnOXHd2MQCL3t3sb1DGGNMBSypxLhDseDpxe4VDM7lk2kgWL99mJfGNMTFhSSWONR1zhSS7GKQPdeO5JRw80szTldt8jMwYY8LzNamIyFwRWS8iVSJya5jt6SLypNu+TESKQ7bd5tavF5GLu2pTPHeKyAYR+UhEvunne+sLbYUkI+ypAMwcO4xZY4fy0N82cazluI/RGWPMJ/mWVEQkGbgPuAQoA64RkbJ2u90I7FPVCcBC4C53bBkwH5gKzAXuF5HkLtq8HhgDTFHVU4DFfr23vhJwM7+601MB+Mb5E9i+7zDPrbLHDRtj+pafPZXZQJWqBlT1KN4v+Xnt9pkHLHLLzwBzRETc+sWqekRVNwFVrr3O2vw6cIeqHgdQ1Vof31ufaJ1OXJIfeU8FYM4pwzllVDb3v1FFy3G7GdIY03f8TCqFQOiF/e1uXdh9VLUZqAfyOjm2szZLgS+LSKWI/EVEJoYLSkRucvtUBoPBHr2xvhIINnZYSLIzIsL/uXACgbpGXvhwp0/RGWPMJw2kgfp0oElVy4HfAA+H20lVH1TVclUtLygo6NMAu6s62EDp8O71UlrNnTqSCcMH86slGzluvRVjTB/xM6nU4I1xtCpy68LuIyIpQA6wp5NjO2tzO/CsW/4jML3X7yCGVNWbTpzfvfGUVklJws0XTGDD7gZeXrsrytEZY0x4fiaVFcBEESkRkTS8gfeKdvtUANe55auAJepVRKwA5rvZYSXARGB5F23+CbjALX8G2ODT++oTrYUkuzPzq73Lp4+itCCLX7y6gWabCWaM6QO+JRU3RnIz8DLwEfCUqq4VkTtE5Aq320NAnohUAbcAt7pj1wJPAeuAl4AFqtrSUZuurf8AvigiHwL/D/hHv95bX6iubX3aY896KgApyUn8y8WTqapt4Nm/W1l8Y4z/ujcC3E2q+iLwYrt1t4csNwFXd3DsncCdkbTp1u8HLutlyHEjUOemEw/veVIBuHjqSGaMGcrC1zZwxYzRZKQmRyM8Y4wJayAN1A8o1bVeIclR2Rm9akdE+P7cKeysb+LRpZujEpsxxnTEkkqcCtRFXkiyK2eV5vGZSQXc90Y19YfskcPGGP9YUolTgWBjrwbp2/v+3CkcbDrGwtf69fwFY0ycs6QSh5qOtbBt36FeDdK3VzY6m2s/NZbH3tvC+l0Ho9auMcaEsqQSh7bsOYR2s5BkJL570WSGZKTwo4q19ix7Y4wvLKnEoeoeFpLsyrCsNL77ucksDezhL2vshkhjTPRZUolDgR4WkozEtbPHcsqobH7y/Doa7UFexpgos6QSh6qDjYzK6X4hyUgkJwn/Pm8qO+qb+MUrNmhvjIkuSypxKBBsiPgRwj1RXpzL/zxzHI+8u4mVW/f5dh5jTOKxpBJnWgtJRns8pb3vzZ3MyOwMbv3DhxxttrpgxpjosKQSZ4IHvUKS430YTwk1JCOVn3xhGut3H+SBt6p9PZcxJnFYUokz1UGvkGRva35FYs4pI/j8aaO5d8lG1u044Pv5jDEDnyWVONM6nTiaNz525sdXTGXooDS+/eRKmo619Mk5jTEDlyWVOBMIRqeQZKRys9L4+dWnsWF3Az99aX2fnNMYM3BZUokzgboGxkepkGSkPjOpgOvPLubhdzbx9sZgn53XGDPwWFKJM9U+TyfuyK2XTGHC8MH889MfsLfxaJ+f3xgzMFhSiSNNx1rYvu+w79OJw8lITebu+TPYd+gY31q8kpbjVhvMGNN9llTiyOY9jagSk54KwNTROfz4iqm8vbGOe5dsjEkMxpj+zZJKHAm0TieOQU+l1fwzxnDlrELufn0jb22w8RVjTPf4mlREZK6IrBeRKhG5Ncz2dBF50m1fJiLFIdtuc+vXi8jFXbUpIr8TkU0issp9zfDzvfmhuta/QpKREhHu/MKpTB4xhG8vXknN/sMxi8UY0//4llREJBm4D7gEKAOuEZGydrvdCOxT1QnAQuAud2wZMB+YCswF7heR5Aja/BdVneG+Vvn13vwSqPOvkGR3ZKYlc/9XZtHcovzjokqrZmyMiZifPZXZQJWqBlT1KLAYmNdun3nAIrf8DDBHRMStX6yqR1R1E1Dl2oukzX4rEGyI6aWvUOMLBnPvtTNZv+sA33lyFcdt4N4YEwE/k0ohsC3k9Xa3Luw+qtoM1AN5nRzbVZt3ishqEVkoIunhghKRm0SkUkQqg8H4GTNQVaqDjTEbpA/n/MnD+eHlZbyybjc/f8VujDTGdG0gDdTfBkwBzgByge+H20lVH1TVclUtLygo6Mv4OhU8eISGI81x01Npdf3ZxVz7qbHc/2Y1f3h/e6zDMcbEOT+TSg0wJuR1kVsXdh8RSQFygD2dHNthm6q6Uz1HgEfwLpX1G1VtNb/ip6cC3sD9j6+YyjkT8vj+H1bbjDBjTKf8TCorgIkiUiIiaXgD7xXt9qkArnPLVwFLVFXd+vludlgJMBFY3lmbIjLKfRfgC8AaH99b1LVOJ+6rQpLdkZqcxAP/43QmjRjC1//7fVZt2x/rkIwxccq3pOLGSG4GXgY+Ap5S1bUicoeIXOF2ewjIE5Eq4BbgVnfsWuApYB3wErBAVVs6atO19biIfAh8COQDP/HrvfkhEGwkMzW5zwpJdteQjFR+d8MZ5A9O56uPLKfKTX82xphQ4nUMElN5eblWVlbGOgwArnt4OcGDR3jxW+fFOpRObdnTyBf/613SkpN4+utnUzg0M9YhGWP6mIi8r6rl4bYNpIH6fi1Q19AnD+bqrXF5Wfzuq7M5eKSZax58j531dnOkMeYESypxoLWQpN+PEI6WaYU5PHrDbPY1HmX+g++xq74p1iEZY+KEJZU4EOtCkj0xc+wwFt04mz0NR7nmN++x+4AlFmOMJZW4UF0b+0KSPTFr7DAW3XAGtQeauObB96xOmDHGkko8CMTpPSqROH1cLotumE3w4BGu/q93qQ7arDBjElmXSUVEJonI6yKyxr2eLiI/8D+0xBGoa2R0TgaD0mJbSLKnyotz+f1NZ3K05ThXP7CUNTX1sQ7JGBMjkfRUfoNXAuUYgKquxrvp0ESJ9wjh/nXpq71phTk8/bWzyUxNZv6D77G0ek+sQzLGxEAkSWWQqi5vt85qoUeJqhIINlLaDy99tVeSn8UzXz+LkTkZXPfwcp5b1b4qjzFmoIskqdSJSCmgACJyFbDT16gSSK0rJNnfeyqtRuVk8vT/PosZY4fyrcWruPu1jSTyDbbGJJpIksoC4NfAFBGpAb4NfM3XqBJIdT8epO/IsKw0HrtxNlfOKmThaxu45akPONLcEuuwjDF9IJKRYVXVz4pIFpCkqgddkUcTBfHwXHo/pKck84urT2N8fhY/f2UDNfsOc99XZlEwJOxjbowxA0QkPZU/AKhqo6oedOue8S+kxFIdbCAzNZmRcVpIsjdEhJsvnMi918xkdc1+Pn/v3/j71n2xDssY46MOk4qITBGRLwI5InJlyNf1wMD7DRgjAfe0x6QkiXUovvn8aaN59uvnkJaSxJd/vZTH3tti4yzGDFCd9VQmA5cDQ4HPh3zNAv7J/9ASw0CYThyJstHZ/Pnmczl3Qj4//NMa/vnp1Rw+auMsxgw0HY6pqOpzwHMicpaqLu3DmBJG07EWavYf5ouzimIdSp/IGZTKQ9edwd2vb+Tu1zeyevt+7r12JlNGZsc6NGNMlEQyprJSRBaIyP0i8nDrl++RJYBNdV4hyf5Q8j5akpKE71w0yatyfOgYV/zqHR5dutkuhxkzQESSVB4DRgIXA2/hPRf+YKdHmIi0PUK4n5S8j6ZPTyrgpW+fxzmledz+3Fr+6dH32dt4NNZhGWN6KZKkMkFVfwg0quoi4DLgU/6GlRj6cyHJaMgfnM7D15/B7ZeX8dcNQeb+8q+8/tHuWIdljOmFSJLKMfd9v4hMA3KA4f6FlDiqgw39upBkNIgIN5xbwh8XnE1uVho3LqrklidXsf+Q9VqM6Y8iSSoPisgw4AdABbAOuMvXqBJEoK4xocZTOjN1dA4VN5/LN+dMpOKDHVy08K+8us56Lcb0N10mFVX9raruU9W/qup4VR0O/CWSxkVkroisF5EqEbk1zPZ0EXnSbV8mIsUh225z69eLyMXdaPMeEYn7h3qoKtW1DQk5ntKRtJQkbrloEn9acA55WWn806OVfPP3K6k9aE+VNKa/6DSpiMhZInKViAx3r6eLyBPAO101LCLJwH3AJUAZcI2IlLXb7UZgn6pOABbiekBuv/nAVGAucL+IJHfVpoiUA8O6ftuxV3vwCI1HWxLiHpXumlbo9Vq+NWciL63ZxZxfvMWjSzfTctxmiBkT7zq7o/5nwMPAF4EXROQnwCvAMmBiBG3PBqpUNaCqR4HFwLx2+8wDFrnlZ4A5IiJu/WJVPaKqm4Aq116HbbqE8zPgexHEFnOthSQHWs2vaElLSeI7F03iL98+j+lFOdz+3Fr+4f53WL19f6xDM8Z0orOeymXATFW9BvgcXnXiM1X1blWN5HpEIbAt5PV2ty7sPqraDNQDeZ0c21mbNwMVqtppWX4RuUlEKkWkMhgMRvA2/FHdOp04QWd+Raq0YDD/feOnuHv+DHbWNzHvvnf44Z/W2PRjY+JUZ0mlqTV5qOo+YKOqbu6TqLpJREYDVwP3drWvqj6oquWqWl5QUOB/cB0IBBsYlDYwC0lGm4gwb0Yhr3/3M/yvM8fx+LItfOZnb/DbtwMcbT4e6/CMMSE6SyrjRaSi9Qsoafe6KzXAmJDXRW5d2H1EJAVvuvKeTo7taP1MYAJQJSKbgUEiUhVBjDFTHWykJH9gF5KMtuyMVH48bxovffvTnD5uGD954SMuWvgWL63ZZXfkGxMnOrtBov34xy+62fYKYKJ79koN3sD7te32qQCuA5YCVwFLVFVd0npCRP4TGI03hrMckHBtqupavLv+ARCRBjf4H7cCwQZmju0XcwrizqQRQ/jdV2fz1oYgd76wjq/99/vMLsnl1kumMMs+U2NiqrOCkm/1pmFVbRaRm4GXgWTgYVVdKyJ3AJWqWgE8BDzmehV78ZIEbr+n8O6JaQYWqGoLQLg2exNnLLQWkrzq9MQoJOmXz0wq4JzS83iychsLX93Alfe/y5wpw/nu5yZTNtqKVBoTC5LIlw3Ky8u1srKyz8/70c4DXHL329xzzUyuOG10n59/IGo80szv3t3Mr9+q5kBTM5dNH8V3PjuJCXZzqTFRJyLvq2p5uG2JWx8khk48QthmfkVLVnoKCy6YwP84cxy/fTvAQ3/bxF8+3Mk/zCziGxeU2tRtY/pIJGVaTJS13qNSYnfTR11OZirf/dxk3v7eBdxwTgnPr97BZ//zLRY8/nfW1NTHOjxjBrwueyoi8meg/TWyeqAS+HWE96yYEIFgA4VDMxO6kKTf8gan84PLy/ja+aU8/LdNPLZ0Cy98uJPzJxew4IIJnFGcG+sQjRmQIumpBIAG4Dfu6wDe81Qmudemm6rdc+mN//IHp/O9uVP4260X8i8XT2b19nqufmApX3pgKa+u222lX4yJskj+VD5bVc8Ief1nEVmhqmeISL+beRVrqkog2GAzv/pYTmYqCy6YwA3nlLB4xVZ+89cA//RoJePyBnH92cVcXT6GwenWczSmtyLpqQwWkbGtL9xy66in1cropt0HvEKSVvI+NjLTkvnqOSW89b0L+NW1M8nLSuPHf17HWf/3df79+XVs23so1iEa069F8qfZd4G/iUg13s2HJcA3RCSLE8UgTYTanvaYb0klllKTk7h8+mgunz6alVv38cg7m1n07mYeeWcTnz1lBF85cxznTci3igfGdFOXSUVVXxSRicAUt2p9yOD8L32LbICqrnPTiYfbmEq8mDl2GDPHDuO2S6fw2NItLF6xjVfW7WZMbibzzxjLl8rHUDAkPdZhGtMvRHoR+XSg2O1/moigqo/6FtUAVl1rhSTj1aicTL43dwrf+uxEXl67myeWbeFnL69n4asb+NzUEVw7exxnl+ZZ78WYTkQypfgxoBRYBbS41QpYUumBQJ0388t7bIyJR+kpyVxx2miuOG001cEGfr9sK8/8fTsvfriLMbmZXDmziCtnFTIuz3qbxrQXSU+lHCjTRK7nEkXVtQ2cPs6KHvYXpQWD+cHlZfzzxZN5ee0unq7czj1LNnL36xs5o3gYV84q4tJTR5GTmRrrUI2JC5EklTV4FYA7ffiV6VrTsRZ21B/m6gKbTtzfZKQmM29GIfNmFLKz/jB/XFnDH97fzm3Pfsi/Vazlc2Uj+OKsIs6dmE9qshWqMIkrkqSSD6wTkeXAkdaVqnqFb1ENUJvqGlG1Rwj3d6NyMvnG+RP4+mdKWb29nmf/vp2KD3bw/OqdDBuUytxpI7ns1NGcOT6XFEswJsFEklR+5HcQiaK15pfdTT8wiAinjRnKaWOG8q+XlfHWhiDPr95Bxaod/H75NvKy0pg7bSSXTx/N7JJckm2A3ySASKYU9+q5KuaE1urEdo/KwJOWksRFZSO4qGwETcdaeHN9LX9evZNn/17D48u2UjAknUunjeTiaSOZXWw9GDNwdZhURORvqnquiBzk5IKSAqiq2lOQuqnaFZLMTEuOdSjGRxmpycydNoq500Zx6GgzSz6u5fkPdrJ4xTYWLd1CTmYqc6YM56KyEXx6UgFZVh7GDCCdPfnxXPd9SN+FM7AFrJBkwhmUltJ2537jkWbe3hjklXW7WfJxLc+urCEtJYlzJ+RzUdkI5pwynOFD7P4l079F9CeSiCQDI0L3V9WtfgU1ELUWkry6fEysQzExkpWe0taDaW45zorN+3h13W5eWbeLJR/XIgKnFQ3l/MkFnD95OKcW5tg4jOl3Irn58f8A/wbsBo671QpM9zGuAae1kKT1VAxASnISZ5XmcVZpHj+8/BQ+3nWQV10P5u7XN/LL1zaSm5XGeRPzOX9yAedNLCB/sJWKMfEvkp7Kt4DJqrqnu42LyFzgbiAZ+K2q/ke77el4d+afDuwBvqyqm92224Ab8e7i/6aqvtxZmyLyEN6NmgJsAK5X1YbuxuyX1kKSNp3YtCcinDIqm1NGZfPNORPZ23iUtzcGeWt9kLc2BHlu1Q5E4NTCHM6fVMCnJxVw2pihdj+MiUuRJJVteE967BZ3yew+4CJgO7BCRCpUdV3IbjcC+1R1gojMB+4CviwiZcB8YCowGnhNRCa5Yzpq8zuqesCd+z+Bm4GTklgs2XRiE6ncrLS2Gy2PH1fW7KjnTZdgfvVGFfcsqSIrLZnZJbmcXZrP2RPyOGVkttUkM3EhkqQSAN4UkRc4+ebH/+ziuNlAlaoGAERkMTAPCE0q8zhxH8wzwK/EK4o1D1isqkeATSJS5dqjozZDEooAmXzyEcgxVR1stEKSptuSkoTpRUOZXjSUb86ZyP5DR3m3eg/vVtfxbvUe3lj/EQDDBqVyVmmel2RK8yjJt/pyJjYiSSpb3Vea+4pUIV4vp9V24FMd7aOqzSJSD+S59e+1O7bQLXfYpog8AlyKl7i+Gy4oEbkJuAlg7Nix4XbxRXWwwQpJml4bOiiNS08dxaWnjgJgZ/1hllbv4Z0qL9G8+OEuAEblZHDm+DzKi4cxuziXCcMH27890yc6TSruEtYkVf1KH8XTK6r6VRfzvcCXgUfC7PMg8CBAeXl5n/VmAsFGKyRpom5UTiZXziriyllFqCpb9hzineo63q3aw9sb6/jjyhrA68mUF+cyuziXM0pymTo628ZkjC86TSqq2iIi40QkTVW7++jgGiB0/myRWxdun+0ikgLk4A3Yd3Zsp226mBcD3yNMUomFw0e9QpJfKrDpxMY/IkJxfhbF+Vl85VPj2pLM8s17WbFpLys27+XVdbsByExNZubYoZxRnMsZxblMH5NDdoZVWja9F+mYyjsiUgE0tq6MYExlBTBRRErwfvHPB65tt08FcB2wFLgKWKKq6s71hBtwHw1MBJbjzez6RJtuHKVUVavc8hXAxxG8tz7RWkjSBulNXwpNMl9y90fVHmhixeZ9rNjsJZl7l2zkuIIITBw+mBljhjJz7DBmjBnKpBFD7D4Z022RJJVq95UERHx3vRsjuRl4GW/678OqulZE7gAqVbUCeAh4zA3E78VLErj9nsIbG2kGFqhqC0AHbSYBi0QkGy/xfAB8PdJY/Raos+nEJj4Mz87gsumjuGy6NyZzoOkYq7buZ9U27+vVdbt5qnI7AFlpyUwvGsqMsUOZOcb7bnf8m65IIj97q7y8XCsrK30/z92vbWThaxv46I65VvfLxLXWS2artu1n5dZ9rNy2n3U7DtB83Ps9UTg0k1MLczi1KIdphTlMG51Nnt2UmXBE5H1VLQ+3LZI76gvwxiemAm1/pqjqhVGLcIAL1FkhSdM/hF4y+8JMb8Jl07EW1u6oZ+XW/azctp+1NfW8tHZX2zGjczK8BFOYw6nue8EQSzSJKpLLX48DTwKXA1/DGwMJ+hnUQNM6ndiY/igjNZnTx+Vy+rjctnX1h4+xdkc9a2rqWVNzgDU19bziJgEAjMzOYFphNtMKc7xqASOzKRqWaTdoJoBIkkqeqj4kIt9yz1Z5S0RW+B3YQKGqbAo2Ul6e2/XOxvQTOZmp7kbL/LZ1B5uOsXbHAZdo6vmwpp7XP66l9Qp7Vloyk0cOYcqobE5x36eMHMIQm3U2oESSVI657ztF5DJgB2C/ISPUWkiy1HoqZoAbkpHKmePzOHN8Xtu6Q0eb2bC7gY93HuCjnQf4aNdBnv9gB08sa27bp2hYJlNGZnPKqCFMGZnNlFFDKM7Lspln/VQkSeUnIpKDd4f6vUA28B1foxpATtT8splfJvEMSkthxpihzBgztG2dqrKzvomPdx3go50H+XjXQT7eeYA31tfS4iYEpKckUVowmIkjBjNx+GAmDB/MhOFDGJc3yG7ajHORPE74ebdYD1zgbzgDj1UnNuZkIsLooZmMHprJhVNGtK1vOtZCVW1DW5KpCjZQuXkfz63a0bZParJQkp/VlmQmDvcST0l+FukpNhEmHkQy+2sS8F/ACFWdJiLTgStU9Se+RzcAVAcbyUpLZkS2zYYxpjMZqclts8hCNR5pJhBsZGPtQTbWNrBxdwPrdhzgpTW7cB0bkgTG5XnJprRgMOPzsygpyKIkP4u8rDSre9aHIrn89RvgX4BfA6jqahF5ArCkEoHqYAMlVkjSmBwGxs0AABMqSURBVB7LSk/h1CLv3phQTcda2FTXyMbaBqp2u4RT28Cb62s51nLi/rshGSleksnPoiR/MCUFWYx306YHp0f08FvTDZF8ooNUdXm7X4rNHe1sThYINlJebIUkjYm2jNTktoebhWpuOU7N/sME6hrZFGxkU533tWLzPp77YAeh93sPH5JOSX4W412vZlxeFmNzBzE2dxBZlnB6JJJPrU5ESnHPJxGRq4CdvkY1QBw+2kLN/sN8Kd8KSRrTV1KSkxiX5yWICyafvK3pWAtb9hxiU13DSUnnlbW72dN4cs3c/MFpbQlmrEs24/K818OHpNvVhw5EklQW4JWKnyIiNcAmoF+Uwo+1TXVe/c3S4Tad2Jh4kJHq3SszeeQnyxjWHzrGlr2NbN17iC17DrHNfV+xeR8VH+xoG7/x2klizDAvyYzJHcS43EGMdQmncOighK6eEcnsrwDwWRHJApJU9aCIfBv4pe/R9XNt04nzbeaXMfEuZ1Aq0wd5T9ls72izd0lty57GtmSzda/39W71Hg4dbTlp/9ysNAqHZlI0LJPCoZkUDsukaNigtuWczIF7w2fEFw1VtTHk5S1YUulSIOh9ZCX51lMxpj9LS0lyA/2f/L+sqtQ1HGXr3kNs33eI7fsOs33fYWr2H2bD7oMs+biWI83HTzpmSEbKSUmnaNggCtuWM8ntxzPWejoS1T/fbR+rDlohSWMGOhGhYEg6BUPSwz7dVVXZ03iUGpdotu87FLJ8mGWBvRw8cvLcp4zUJEbnZDIyJ4ORORlty6NCXg8dlBqXiaenSSVx6+V3Q6DOCkkak+hEhPzB6eQPTue0MZ+8tAZegc6afS7h7D9Mzb7D7DzQxK76Jt6r3sPug0faqg20Sk9Jaksyo3IyGdWWdE4sx6LH02FSEZGDhE8eAmT6FtEAoaoEgo18yQpJGmO6kJOZSk5mKmWjs8Nubzmu1DUcYWd9Ezv3H2ZnfRO7DjSxY/9hdtU3sXzTXnYfaGp77k2rtJQkRmZnMDI7gxE5GYwYks7InAxGZGfw6UkFvoztdJhUVDXipzyaT9p1oIlDVkjSGBMFyUnCiGwvGczooLdzPDTx1Dexq/7wieUDTazevp9d9U1t4ztLvvuZvk0qpndaB+mt5pcxpi8kJQnDszMYnp3BaR3cGqeqHDjczK4DTYzJHeRLHJZUfGLViY0x8UZEyBmUSs4g/6Y0+1pDWkTmish6EakSkVvDbE8XkSfd9mUiUhyy7Ta3fr2IXNxVmyLyuFu/RkQeFpGYTgQPWCFJY0wC8i2piEgycB9wCVAGXCMiZe12uxHYp6oTgIXAXe7YMmA+MBWYC9wvIsldtPk4MAU4FW8iwT/69d4i4T1CeHBcTvkzxhi/+NlTmQ1UqWpAVY8Ci4F57faZByxyy88Ac8T7LTwPWKyqR1R1E1Dl2uuwTVV9UR1gOVDk43vrUiDYaNOJjTEJx8+kUghsC3m93a0Lu4+qNuM9CCyvk2O7bNNd9vqfwEvhghKRm0SkUkQqg8FgN99SZFoLSdogvTEm0QzE53LeD/xVVd8Ot1FVH1TVclUtLygo8CWAQF3rIL31VIwxicXP2V81QOjEtiK3Ltw+20UkBcgB9nRxbIdtisi/AQXA/45C/D3WOp3YCkkaYxKNnz2VFcBEESkRkTS8gfeKdvtUANe55auAJW5MpAKY72aHlQAT8cZJOmxTRP4RuBi4RlWPE0PVwQZErJCkMSbx+NZTUdVmEbkZeBlIBh5W1bUicgdQqaoVwEPAYyJSBezFSxK4/Z4C1uE9ZXKBqrYAhGvTnfIBYAuw1M24elZV7/Dr/XUmEGxkdI4VkjTGJB5fb35U1ReBF9utuz1kuQm4uoNj7wTujKRNtz5ubuQM1DVQOtwufRljEs9AHKiPqdZCkuPt0pcxJgFZUomytkKS1lMxxiQgSypRVl3rCklaT8UYk4AsqUTZiXtUrKdijEk8llSizApJGmMSmSWVKLNCksaYRGZJJcoCwUZ72qMxJmFZUomiQ0ebqdl/2MZTjDEJy5JKFG2qczW/rKdijElQllSiqNqeS2+MSXCWVKIoYIUkjTEJzpJKFAWCjRQOzSQj1QpJGmMSkyWVKGqdTmyMMYnKkkqUHD+uNp3YGJPwLKlEya4DTRw+1mI9FWNMQrOkEiWtjxC2QpLGmERmSSVKWgtJWsl7Y0wis6QSJdW1DWSlJTN8iBWSNMYkLksqURKoa6R0uBWSNMYkNl+TiojMFZH1IlIlIreG2Z4uIk+67ctEpDhk221u/XoRubirNkXkZrdORSTfz/cVTnVtgz1C2BiT8HxLKiKSDNwHXAKUAdeISFm73W4E9qnqBGAhcJc7tgyYD0wF5gL3i0hyF22+A3wW2OLXe+rIoaPN7KhvsplfxpiE52dPZTZQpaoBVT0KLAbmtdtnHrDILT8DzBHv+tE8YLGqHlHVTUCVa6/DNlV1papu9vH9dChgNb+MMQbwN6kUAttCXm9368Luo6rNQD2Q18mxkbTZ5wJWndgYY4AEHKgXkZtEpFJEKoPBYFTatEKSxhjj8TOp1ABjQl4XuXVh9xGRFCAH2NPJsZG02SlVfVBVy1W1vKCgoDuHdqjaCkkaYwzgb1JZAUwUkRIRScMbeK9ot08FcJ1bvgpYoqrq1s93s8NKgInA8gjb7HOBYIONpxhjDD4mFTdGcjPwMvAR8JSqrhWRO0TkCrfbQ0CeiFQBtwC3umPXAk8B64CXgAWq2tJRmwAi8k0R2Y7Xe1ktIr/1672Fai0kaeMpxhgDKX42rqovAi+2W3d7yHITcHUHx94J3BlJm279PcA9vQy526yQpDHGnJBwA/XRdmI6sfVUjDHGkkovVQddIUnrqRhjjCWV3goEGxicnmKFJI0xBksqvVbtBumtkKQxxlhS6bVA0ApJGmNMK0sqvdBaSNLGU4wxxmNJpRdaZ37ZdGJjjPFYUumF1kKSpcPt8pcxxoAllV6prvUKSRbnWVIxxhiwpNIrgbpGioZZIUljjGllSaUXvEcI23iKMca0sqTSQ8ePK5vqrJCkMcaEsqTSQztdIUmbTmyMMSdYUumhgKv5ZT0VY4w5wZJKD7XeozLBeirGGNPGkkoPVbtCkgVWSNIYY9pYUumhQLCRUiskaYwxJ7Gk0kPVwQYrz2KMMe1YUumBQ0eb2VnfZNWJjTGmHUsqPdD2COHh1lMxxphQviYVEZkrIutFpEpEbg2zPV1EnnTbl4lIcci229z69SJycVdtikiJa6PKtZnm1/uqtunExhgTlm9JRUSSgfuAS4Ay4BoRKWu3243APlWdACwE7nLHlgHzganAXOB+EUnuos27gIWurX2ubV8Ego1WSNIYY8Lws6cyG6hS1YCqHgUWA/Pa7TMPWOSWnwHmiDedah6wWFWPqOomoMq1F7ZNd8yFrg1cm1/w641VBxuskKQxxoSR4mPbhcC2kNfbgU91tI+qNotIPZDn1r/X7thCtxyuzTxgv6o2h9n/JCJyE3ATwNixY7v3jpxTRmVTNGxQj441xpiBzM+kEpdU9UHgQYDy8nLtSRsLLpgQ1ZiMMWag8PPyVw0wJuR1kVsXdh8RSQFygD2dHNvR+j3AUNdGR+cyxhjjMz+TygpgopuVlYY38F7Rbp8K4Dq3fBWwRFXVrZ/vZoeVABOB5R216Y55w7WBa/M5H9+bMcaYMHy7/OXGSG4GXgaSgYdVda2I3AFUqmoF8BDwmIhUAXvxkgRuv6eAdUAzsEBVWwDCtelO+X1gsYj8BFjp2jbGGNOHxPsjPzGVl5drZWVlrMMwxph+RUTeV9XycNvsjnpjjDFRY0nFGGNM1FhSMcYYEzWWVIwxxkRNQg/Ui0gQ2NLDw/OBuiiGEy0WV/dYXN1jcXXPQI1rnKoWhNuQ0EmlN0SksqPZD7FkcXWPxdU9Flf3JGJcdvnLGGNM1FhSMcYYEzWWVHruwVgH0AGLq3ssru6xuLon4eKyMRVjjDFRYz0VY4wxUWNJxRhjTNRYUukBEZkrIutFpEpEbu2D820WkQ9FZJWIVLp1uSLyqohsdN+HufUiIve42FaLyKyQdq5z+28Ukes6Ol8XsTwsIrUisiZkXdRiEZHT3XutcsdKL+L6kYjUuM9tlYhcGrLtNneO9SJyccj6sD9b97iFZW79k+7RC13FNEZE3hCRdSKyVkS+FQ+fVydxxfrzyhCR5SLygYvrx521Jd6jMZ5065eJSHFP4+1hXL8TkU0hn9cMt77P/t27Y5NFZKWIPB8Pnxeqal/d+MIruV8NjAfSgA+AMp/PuRnIb7fup8CtbvlW4C63fCnwF0CAM4Flbn0uEHDfh7nlYT2I5dPALGCNH7HgPTfnTHfMX4BLehHXj4B/DrNvmfu5pQMl7ueZ3NnPFngKmO+WHwC+HkFMo4BZbnkIsMGdO6afVydxxfrzEmCwW04Flrn3FrYt4BvAA255PvBkT+PtYVy/A64Ks3+f/bt3x94CPAE839ln31efl/VUum82UKWqAVU9CiwG5sUgjnnAIre8CPhCyPpH1fMe3hMxRwEXA6+q6l5V3Qe8Cszt7klV9a94z76JeixuW7aqvqfev/ZHQ9rqSVwdmQcsVtUjqroJqML7uYb92bq/Gi8EngnzHjuLaaeq/t0tHwQ+AgqJ8efVSVwd6avPS1W1wb1MdV/aSVuhn+MzwBx37m7F24u4OtJn/+5FpAi4DPite93ZZ98nn5clle4rBLaFvN5O5/8ho0GBV0TkfRG5ya0boao73fIuYEQX8fkZd7RiKXTL0YzxZncJ4mFxl5l6EFcesF9Vm3sal7vUMBPvr9y4+bzaxQUx/rzcpZxVQC3eL93qTtpqO7/bXu/OHfX/A+3jUtXWz+tO93ktFJH09nFFeP7e/Bx/CXwPOO5ed/bZ98nnZUmlfzhXVWcBlwALROTToRvdXzdxMTc8nmIB/gsoBWYAO4FfxCIIERkM/AH4tqoeCN0Wy88rTFwx/7xUtUVVZwBFeH8pT+nrGMJpH5eITANuw4vvDLxLWt/vy5hE5HKgVlXf78vzdsWSSvfVAGNCXhe5db5R1Rr3vRb4I95/tt2u24z7XttFfH7GHa1YatxyVGJU1d3ul8Fx4Dd4n1tP4tqDdwkjpd36LolIKt4v7sdV9Vm3OuafV7i44uHzaqWq+4E3gLM6aavt/G57jju3b/8HQuKa6y4jqqoeAR6h559XT3+O5wBXiMhmvEtTFwJ3E+vPq6tBF/v6xKBYCt4AWwknBq+m+ni+LGBIyPK7eGMhP+Pkwd6fuuXLOHmQcLlbnwtswhsgHOaWc3sYUzEnD4hHLRY+OWB5aS/iGhWy/B2868YAUzl5YDKANyjZ4c8WeJqTBz+/EUE8gnd9/Jft1sf08+okrlh/XgXAULecCbwNXN5RW8ACTh54fqqn8fYwrlEhn+cvgf+Ixb97d/z5nBioj+3n1ZNfKon+hTe7YwPe9d5/9flc490P8wNgbev58K6Fvg5sBF4L+ccpwH0utg+B8pC2bsAbhKsCvtrDeH6Pd2nkGN411hujGQtQDqxxx/wKV/Whh3E95s67Gqjg5F+a/+rOsZ6QmTYd/Wzdz2G5i/dpID2CmM7Fu7S1Gljlvi6N9efVSVyx/rymAyvd+dcAt3fWFpDhXle57eN7Gm8P41riPq81wH9zYoZYn/27Dzn+fE4klZh+XlamxRhjTNTYmIoxxpiosaRijDEmaiypGGOMiRpLKsYYY6LGkooxxpiosaRiTDeJSF5IZdpdcnJl306r8YpIuYjc083z3eAq2K4WkTUiMs+tv15ERvfmvRgTbTal2JheEJEfAQ2q+vOQdSl6ovZSb9svAt7Cqypc70qrFKjqJhF5E6+qcGU0zmVMNFhPxZgocM/WeEBElgE/FZHZIrLUPefiXRGZ7PY7P+S5Fz9yhRvfFJGAiHwzTNPDgYNAA4CqNriEchXeDXOPux5Spnsmx1uu8OjLIaVg3hSRu91+a0RkdpjzGBMVllSMiZ4i4GxVvQX4GDhPVWcCtwP/t4NjpuCVRJ8N/JuryRXqA2A3sElEHhGRzwOo6jNAJfAV9QodNgP34j3f43TgYeDOkHYGuf2+4bYZ44uUrncxxkToaVVtccs5wCIRmYhXEqV9smj1gnoFCY+ISC1eGfy2Muiq2iIic/Eq4c4BForI6ar6o3btTAamAa96j8ggGa9sTavfu/b+KiLZIjJUveKIxkSVJRVjoqcxZPnfgTdU9R/cM0ve7OCYIyHLLYT5P6newOdyYLmIvIpXEfdH7XYTYK2qntXBedoPntpgqvGFXf4yxh85nCgTfn1PGxGR0RLyjHO8Z51sccsH8R4HDF4hwAIROcsdlyoiU0OO+7Jbfy5Qr6r1PY3JmM5YT8UYf/wU7/LXD4AXetFOKvBzN3W4CQgCX3Pbfgc8ICKH8Z47chVwj4jk4P3f/iVeZWuAJhFZ6dq7oRfxGNMpm1JszABnU49NX7LLX8YYY6LGeirGGGOixnoqxhhjosaSijHGmKixpGKMMSZqLKkYY4yJGksqxhhjoub/A2wc9nSuF+XGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Optimizor:\n",
    "\n",
    "# Optimizor\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "    \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "# Learning rate curve:\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and metric\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # no mask:\n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #loss_ = loss_object(real, pred)\n",
    "\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "    loss = tf.cast(tf.reduce_sum(real-pred),dtype=tf.float32)\n",
    "  \n",
    "    #return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data 0.00 percent\n",
      "Prepare data 24.05 percent\n",
      "Prepare data 48.10 percent\n",
      "Prepare data 72.15 percent\n",
      "Prepare data 96.20 percent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# prepare data : 180 for 1\n",
    "index_name=0\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# min-max scaler\n",
    "np_scaled = min_max_scaler.fit_transform(df[names_array])\n",
    "\n",
    "#df_scaled = pd.DataFrame(np_scaled,columns=names_array)\n",
    "\n",
    "df_scaled = pd.DataFrame(df[names_array],columns=names_array)\n",
    "X = np.zeros((df_scaled.shape[0]-input_length,input_length,1),dtype=float)\n",
    "y = df_scaled[names_array[index_name]][input_length:]\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if i%10000==0:\n",
    "        print(\"Prepare data %.2f percent\"%(100*i/len(y)))\n",
    "    X[i,:,0] = df_scaled[i:i+input_length][names_array[index_name]].values\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n# split train test:\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\\n\\nprint(\"Finished preparing data\")   \\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \n",
    "# split train test:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "print(\"Finished preparing data\")   \n",
    "\n",
    "\"\"\"\n",
    "# use tf built in function for train test split:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch =8\n",
    "temp_input = tf.random.uniform((batch, 180), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((batch, 1), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "temp_input = tf.cast(temp_input,dtype=tf.float32)\n",
    "temp_target = tf.cast(temp_target,dtype=tf.float32)\n",
    "\n",
    "\n",
    "model = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,input_length=input_length,output_length=output_length,dff=dff,training=True)\n",
    "\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "\n",
    "\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model.call(inp,tar,training=True)\n",
    "        loss = loss_function(tar, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    #temp = np.nansum(abs(np.array(predictions).ravel()-temp_target))\n",
    "    #print(temp)\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar, predictions)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = tf.cast(X,dtype=tf.float32)\n",
    "y = tf.cast(y,dtype=tf.float32)\n",
    "n_epoch = 10\n",
    "# N//batch\n",
    "loss_array = []\n",
    "N = len(y)\n",
    "\n",
    "for j in range(n_epoch):\n",
    "    \n",
    "    for i in range(N//batch):\n",
    "        inp, tar=X[batch*i:min(batch*i+batch,N),:,0],y[batch*i:min(batch*i+batch,N)]\n",
    "        tar = np.atleast_2d(tar).T\n",
    "        temp = train_step(inp, tar)\n",
    "        if i%200==0:\n",
    "            print(\"Doing %d (%d) batch in epoch %d loss=%.2f\"%(i,N//batch,j,temp))\n",
    "\n",
    "        loss_array.append(temp)\n",
    "        #train_step(temp_input,temp_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model.call(inp,tar,training=True)\n",
    "        loss = loss_function(tar, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    #temp = np.nansum(abs(np.array(predictions).ravel()-temp_target))\n",
    "    #print(temp)\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar, predictions)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "train_step(inp,tar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
